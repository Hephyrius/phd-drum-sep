{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b3b1001-adaf-47b4-a7d7-c3f5812fe8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pywt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchaudio.pipelines import HDEMUCS_HIGH_MUSDB\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import random\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import wandb\n",
    "import auraloss\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "import pretty_midi\n",
    "import matplotlib.pyplot as plt\n",
    "from torchaudio.pipelines import HDEMUCS_HIGH_MUSDB\n",
    "print(torch.cuda.is_available())\n",
    "import plotly.graph_objects as go\n",
    "from torch.optim import lr_scheduler\n",
    "from demucs import pretrained, htdemucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7157acd4-f442-491c-b3cc-4667b1f51243",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 3407\n",
    "torch.manual_seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "torch.cuda.manual_seed(seed_value)\n",
    "torch.cuda.manual_seed_all(seed_value)\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c78a41e-68bf-4b4c-a0d1-ec6c45ca06bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:/Github/phd-drum-sep/Data/musdb18hq/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71404093-be7b-46f9-a7e4-d097802204ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = list(os.listdir(path+'train'))\n",
    "test = list(os.listdir(path+'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95f2f38e-fb82-4764-8fe4-fb385dee58b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 7364.50it/s]\n"
     ]
    }
   ],
   "source": [
    "all_scenes = {}\n",
    "counter = 0\n",
    "for idx, val in tqdm(enumerate(train)):\n",
    "    p = path + 'train/' + val + \"/\"\n",
    "    info = torchaudio.info(f\"{p}mixture.wav\")\n",
    "    seconds = info.num_frames // 44100\n",
    "    for i in range(0, seconds - 10, 10):\n",
    "        start_point = i * 44100\n",
    "        if start_point + 441000 < info.num_frames:\n",
    "            all_scenes[counter] = {'music_path': p, 'start_point': start_point, 'length': 441000, 'frames' : info.num_frames}\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d70dd62-59a8-4f94-ab3c-0e627c8710d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataGenerator(Dataset):\n",
    "    def __init__(self, data, sample_rate=44100, segment_length = 10, reference=\"drums.wav\"):\n",
    "        self.data = data\n",
    "        self.sample_rate = sample_rate\n",
    "        self.segment_length = sample_rate * segment_length\n",
    "        self.reference = reference\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def load_audio(self, path, start_point, filename):\n",
    "        audio_tensors = []\n",
    "        file = filename\n",
    "        segment, _ = torchaudio.load(f\"{path}/{file}\", frame_offset=start_point, num_frames=self.segment_length)\n",
    "        audio_tensors.append(segment)\n",
    "        return torch.cat(audio_tensors, dim=0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        sample = self.data[idx]\n",
    "\n",
    "        # Load audio as a tensor\n",
    "        audio_path = sample['music_path']\n",
    "\n",
    "        start_point = sample['start_point']\n",
    "\n",
    "        mixture_tensor = self.load_audio(audio_path, start_point,'mixture.wav')\n",
    "        reference_tensor = self.load_audio(audio_path, start_point, self.reference)\n",
    "        return mixture_tensor, reference_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f575f345-e823-4279-b9ac-7cf17d94edde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data, batch_size=32, num_workers=0, persistent_workers=False, shuffle=False):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.persistent_workers=persistent_workers\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Split your data here if necessary, e.g., into train, validation, test\n",
    "        self.dataset = AudioDataGenerator(self.data)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.dataset, batch_size=self.batch_size, shuffle=self.shuffle, num_workers = self.num_workers, persistent_workers=self.persistent_workers)\n",
    "\n",
    "    # Implement val_dataloader() and test_dataloader() if you have validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a19cca7-a692-41e6-b9f9-7666812febbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, sample_rate=44100, n_cc=32, hop_length=512, n_fft=2048):\n",
    "        super(Encoder, self).__init__()\n",
    "        # Define down-sampling layers for one encoder head\n",
    "        self.down1 = nn.Sequential(nn.Conv1d(2, 16, kernel_size=15, stride=2, padding=7),  nn.Softsign())\n",
    "        self.down2 = nn.Sequential(nn.Conv1d(16, 32, kernel_size=15, stride=2, padding=7),  nn.Softsign())\n",
    "        self.down3 = nn.Sequential(nn.Conv1d(32, 64, kernel_size=13, stride=2, padding=6),  nn.Softsign())\n",
    "        self.down4 = nn.Sequential(nn.Conv1d(64, 128, kernel_size=11, stride=2, padding=5),  nn.Softsign())\n",
    "        self.down5 = nn.Sequential(nn.Conv1d(128, 256, kernel_size=9, stride=2, padding=4),  nn.Softsign())\n",
    "        self.down6 = nn.Sequential(nn.Conv1d(256, 1024, kernel_size=7, stride=2, padding=3),  nn.Softsign())\n",
    "        self.down7 = nn.Sequential(nn.Conv1d(1024, 1024, kernel_size=5, stride=2, padding=2),  nn.Softsign())\n",
    "        self.down8 = nn.Sequential(nn.Conv1d(1024, 2048, kernel_size=5, stride=2, padding=2),  nn.Softsign())\n",
    "        self.down9 = nn.Sequential(nn.Conv1d(2048, 4096, kernel_size=5, stride=2, padding=2),  nn.Softsign())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "        d5 = self.down5(d4)        \n",
    "        d6 = self.down6(d5)\n",
    "        d7 = self.down7(d6)\n",
    "        d8 = self.down8(d7)\n",
    "        d9 = self.down9(d8)\n",
    "\n",
    "        return [d1, d2, d3, d4, d5, d6, d7, d8, d9]  # Return all intermediate outputs for skip connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e19e215b-7d0d-42fb-80a3-bfa02c5ec8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveUNet(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(WaveUNet, self).__init__()\n",
    "        # Create 4 separate encoder heads\n",
    "        self.encoders = Encoder()\n",
    "\n",
    "        # Define the up-sampling layers\n",
    "        # Adjust the number of input channels according to the concatenated encoder outputs\n",
    "        self.up9 = nn.Sequential(nn.ConvTranspose1d(4096, 2048, kernel_size=5, stride=2, padding=2, output_padding=0),  nn.Softsign())\n",
    "        self.up8 = nn.Sequential(nn.ConvTranspose1d(2048, 1024, kernel_size=5, stride=2, padding=2, output_padding=1),  nn.Softsign())\n",
    "        self.up7 = nn.Sequential(nn.ConvTranspose1d(1024, 512, kernel_size=5, stride=2, padding=2, output_padding=0), nn.Softsign())\n",
    "        self.up6 = nn.Sequential(nn.ConvTranspose1d(512, 256, kernel_size=7, stride=2, padding=3, output_padding=1),  nn.Softsign())\n",
    "        self.up5 = nn.Sequential(nn.ConvTranspose1d(256, 128, kernel_size=9, stride=2, padding=4, output_padding=0),  nn.Softsign())\n",
    "        self.up4 = nn.Sequential(nn.ConvTranspose1d(128, 64, kernel_size=11, stride=2, padding=5, output_padding=0), nn.Softsign())\n",
    "        self.up3 = nn.Sequential(nn.ConvTranspose1d(64, 32, kernel_size=13, stride=2, padding=6, output_padding=1), nn.Softsign())\n",
    "        self.up2 = nn.Sequential(nn.ConvTranspose1d(32, 16, kernel_size=15, stride=2, padding=7, output_padding=1), nn.Softsign())\n",
    "        self.up1 = nn.Sequential(nn.ConvTranspose1d(16, 2, kernel_size=15, stride=2, padding=7, output_padding=1))\n",
    "        \n",
    "         # Additional convolutions for processing concatenated skip connections\n",
    "        self.conv_skip_8 = nn.Sequential(nn.Conv1d(4096, 2048, kernel_size=5, padding=2), nn.Softsign())  # 1024 (from up3) + 512 (skip)\n",
    "        self.conv_skip_7 = nn.Sequential(nn.Conv1d(2048, 1024, kernel_size=5, padding=2), nn.Softsign())  # 1024 (from up3) + 512 (skip)\n",
    "        self.conv_skip_6 = nn.Sequential(nn.Conv1d(1536, 512, kernel_size=5, padding=2), nn.Softsign())  # 1024 (from up3) + 512 (skip)\n",
    "        self.conv_skip_5 = nn.Sequential(nn.Conv1d(512, 256, kernel_size=5, padding=2), nn.Softsign())  # 512 (from up3) + 256 (skip)\n",
    "        self.conv_skip_4 = nn.Sequential(nn.Conv1d(256, 128, kernel_size=5, padding=2), nn.Softsign())  # 256 (from up3) + 128 (skip)\n",
    "        self.conv_skip_3 = nn.Sequential(nn.Conv1d(128, 64, kernel_size=5, padding=2), nn.Softsign())  # 128 (from up3) + 64 (skip)\n",
    "        self.conv_skip_2 = nn.Sequential(nn.Conv1d(64, 32, kernel_size=5, padding=2), nn.Softsign())  # 64 (from up3) + 32 (skip)\n",
    "        self.conv_skip_1 = nn.Sequential(nn.Conv1d(32, 16, kernel_size=5, padding=2), nn.Softsign())  # 32 (from up2) + 16 (skip)\n",
    "\n",
    "\n",
    "        self.loss_fn = auraloss.freq.MultiResolutionSTFTLoss(\n",
    "                fft_sizes=[1024, 2048, 4096],\n",
    "                hop_sizes=[256, 512, 1024],\n",
    "                win_lengths=[1024, 2048, 4096],\n",
    "                scale=\"mel\", \n",
    "                n_bins=160,\n",
    "                sample_rate=44100,\n",
    "                device=\"cuda\"\n",
    "            )\n",
    "\n",
    "        self.loss_fn_2 = auraloss.time.SISDRLoss()\n",
    "    \n",
    "        self.loss_fn_3 = torch.nn.L1Loss()\n",
    "\n",
    "\n",
    "    def forward(self, audio):\n",
    "        skip_connections = []\n",
    "        encoded_output = []\n",
    "\n",
    "        audio_input = audio\n",
    "        \n",
    "        outputs = self.encoders(audio_input)\n",
    "        encoded_output.append(outputs[-1])  # Use the last output for the main path\n",
    "        skip_connections.append(outputs[:-1])  # Collect earlier outputs for skip connections\n",
    "\n",
    "        # Combine the encoded representations with feature embeddings\n",
    "        combined = torch.cat([o for o in encoded_output], dim=1)\n",
    "\n",
    "        #8\n",
    "        u9 = self.up9(combined)\n",
    "\n",
    "        #8\n",
    "        skip_8 = torch.cat([u9, skip_connections[0][-1]], dim=1)  \n",
    "        skip_8 = self.conv_skip_8(skip_8)  # Convolution to adjust channel size\n",
    "        u8 = self.up8(skip_8)\n",
    "\n",
    "\n",
    "        #7\n",
    "        skip_7 = torch.cat([u8, skip_connections[0][-2]], dim=1)  \n",
    "        skip_7 = self.conv_skip_7(skip_7)  # Convolution to adjust channel size\n",
    "        u7 = self.up7(skip_7)\n",
    "\n",
    "        #6\n",
    "        skip_6 = torch.cat([u7, skip_connections[0][-3]], dim=1)  \n",
    "        skip_6 = self.conv_skip_6(skip_6)  # Convolution to adjust channel size\n",
    "        u6 = self.up6(skip_6)\n",
    "\n",
    "        #5\n",
    "        skip_5 = torch.cat([u6, skip_connections[0][-4]], dim=1)  \n",
    "        skip_5 = self.conv_skip_5(skip_5)  # Convolution to adjust channel size\n",
    "        u5 = self.up5(skip_5)\n",
    "\n",
    "        #4\n",
    "        skip_4 = torch.cat([u5, skip_connections[0][-5]], dim=1)  \n",
    "        skip_4 = self.conv_skip_4(skip_4)  # Convolution to adjust channel size\n",
    "        u4 = self.up4(skip_4)\n",
    "\n",
    "        #3\n",
    "        skip_3 = torch.cat([u4, skip_connections[0][-6]], dim=1)  \n",
    "        skip_3 = self.conv_skip_3(skip_3)  # Convolution to adjust channel size\n",
    "        u3 = self.up3(skip_3)\n",
    "\n",
    "        #2\n",
    "        skip_2 = torch.cat([u3, skip_connections[0][-7]], dim=1)  \n",
    "        skip_2 = self.conv_skip_2(skip_2)  # Convolution to adjust channel size\n",
    "        u2 = self.up2(skip_2)\n",
    "\n",
    "        #1\n",
    "        skip_1 = torch.cat([u2, skip_connections[0][-8]], dim=1)  \n",
    "        skip_1 = self.conv_skip_1(skip_1)  # Convolution to adjust channel size\n",
    "        u1 = self.up1(skip_1)\n",
    "        \n",
    "        # Output\n",
    "        out = u1\n",
    "        return out\n",
    "\n",
    "    def compute_loss(self, outputs, ref_signals):\n",
    "        loss = self.loss_fn(outputs, ref_signals) + self.loss_fn_2(outputs, ref_signals) +  self.loss_fn_3(outputs, ref_signals)\n",
    "        return loss\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop. It is independent of forward\n",
    "        audio, reference = batch\n",
    "        \n",
    "        outputs = self.forward(audio)\n",
    "\n",
    "        if batch_idx % 512 == 0:\n",
    "            input_signal = audio[0].cpu().detach().numpy().T\n",
    "            generated_signal = outputs[0].cpu().detach().numpy().T\n",
    "            reference_signal = reference[0].cpu().detach().numpy().T \n",
    "            wandb.log({'audio_input': [wandb.Audio(input_signal, caption=\"Input\", sample_rate=44100)]})\n",
    "            wandb.log({'reference_signal': [wandb.Audio(reference_signal, caption=\"Reference\", sample_rate=44100)]})\n",
    "            wandb.log({'audio_output': [wandb.Audio(generated_signal, caption=\"Output\", sample_rate=44100)]})\n",
    "             \n",
    "        loss = self.compute_loss(outputs, reference)         \n",
    "\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Define your optimizer and optionally learning rate scheduler here\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.99)\n",
    "        return [optimizer], [scheduler]\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d9bd30a-a79f-4815-b263-075a2e6888d8",
   "metadata": {},
   "source": [
    "model = WaveUNet()\n",
    "model(torch.randn(1,2,441000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88a25bbb-3082-4ea6-90f3-c05f27fe6f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WaveUNet()\n",
    "wandb_logger = WandbLogger(project='UnetWithFeats', log_model='all')\n",
    "audio_data_module = AudioDataModule(all_scenes, batch_size=1, num_workers=0, persistent_workers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7798c878-d348-45f3-88fd-158b0099a0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=1000,\n",
    "    accelerator=\"gpu\", \n",
    "    devices=-1,\n",
    "    logger=wandb_logger,\n",
    "    gradient_clip_val=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edbb72cc-4767-4c87-bb59-c08d9bcfef46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhephyrius\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20240317_024625-vnkw1ejx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hephyrius/UnetWithFeats/runs/vnkw1ejx' target=\"_blank\">divine-pine-13</a></strong> to <a href='https://wandb.ai/hephyrius/UnetWithFeats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hephyrius/UnetWithFeats' target=\"_blank\">https://wandb.ai/hephyrius/UnetWithFeats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hephyrius/UnetWithFeats/runs/vnkw1ejx' target=\"_blank\">https://wandb.ai/hephyrius/UnetWithFeats/runs/vnkw1ejx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type                    | Params\n",
      "---------------------------------------------------------\n",
      "0  | encoders    | Encoder                 | 59.9 M\n",
      "1  | up9         | Sequential              | 41.9 M\n",
      "2  | up8         | Sequential              | 10.5 M\n",
      "3  | up7         | Sequential              | 2.6 M \n",
      "4  | up6         | Sequential              | 917 K \n",
      "5  | up5         | Sequential              | 295 K \n",
      "6  | up4         | Sequential              | 90.2 K\n",
      "7  | up3         | Sequential              | 26.7 K\n",
      "8  | up2         | Sequential              | 7.7 K \n",
      "9  | up1         | Sequential              | 482   \n",
      "10 | conv_skip_8 | Sequential              | 41.9 M\n",
      "11 | conv_skip_7 | Sequential              | 10.5 M\n",
      "12 | conv_skip_6 | Sequential              | 3.9 M \n",
      "13 | conv_skip_5 | Sequential              | 655 K \n",
      "14 | conv_skip_4 | Sequential              | 163 K \n",
      "15 | conv_skip_3 | Sequential              | 41.0 K\n",
      "16 | conv_skip_2 | Sequential              | 10.3 K\n",
      "17 | conv_skip_1 | Sequential              | 2.6 K \n",
      "18 | loss_fn     | MultiResolutionSTFTLoss | 0     \n",
      "19 | loss_fn_2   | SISDRLoss               | 0     \n",
      "20 | loss_fn_3   | L1Loss                  | 0     \n",
      "---------------------------------------------------------\n",
      "173 M     Trainable params\n",
      "0         Non-trainable params\n",
      "173 M     Total params\n",
      "694.259   Total estimated model params size (MB)\n",
      "C:\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a539ca72c5e4ff8abced96ccb26ebbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_data_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    576\u001b[0m     ckpt_path,\n\u001b[0;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    579\u001b[0m )\n\u001b[1;32m--> 580\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:989\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 989\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    991\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    994\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1035\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1033\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[0;32m   1034\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m-> 1035\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:203\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance()\n\u001b[1;32m--> 203\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_advance_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:374\u001b[0m, in \u001b[0;36m_FitLoop.on_advance_end\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    372\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_train_epoch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m, monitoring_callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    373\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_train_epoch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 374\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_callback_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_train_epoch_end\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitoring_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    376\u001b[0m trainer\u001b[38;5;241m.\u001b[39m_logger_connector\u001b[38;5;241m.\u001b[39mon_epoch_end()\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_loop\u001b[38;5;241m.\u001b[39m_num_ready_batches_reached():\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;66;03m# if we are restarting and the above condition holds, it's because we are reloading an epoch-end checkpoint.\u001b[39;00m\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;66;03m# since metric-based schedulers require access to metrics and those are not currently saved in the\u001b[39;00m\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;66;03m# checkpoint, the plateau schedulers shouldn't be updated\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:208\u001b[0m, in \u001b[0;36m_call_callback_hooks\u001b[1;34m(trainer, hook_name, monitoring_callbacks, *args, **kwargs)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn):\n\u001b[0;32m    207\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Callback]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcallback\u001b[38;5;241m.\u001b[39mstate_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 208\u001b[0m             \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pl_module:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:313\u001b[0m, in \u001b[0;36mModelCheckpoint.on_train_epoch_end\u001b[1;34m(self, trainer, pl_module)\u001b[0m\n\u001b[0;32m    311\u001b[0m monitor_candidates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_monitor_candidates(trainer)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_every_n_epochs \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (trainer\u001b[38;5;241m.\u001b[39mcurrent_epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_every_n_epochs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 313\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_topk_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_last_checkpoint(trainer, monitor_candidates)\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:372\u001b[0m, in \u001b[0;36mModelCheckpoint._save_topk_checkpoint\u001b[1;34m(self, trainer, monitor_candidates)\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_monitor_checkpoint(trainer, monitor_candidates)\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 372\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_none_monitor_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor_candidates\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:700\u001b[0m, in \u001b[0;36mModelCheckpoint._save_none_monitor_checkpoint\u001b[1;34m(self, trainer, monitor_candidates)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;66;03m# set the best model path before saving because it will be part of the state.\u001b[39;00m\n\u001b[0;32m    699\u001b[0m previous, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_model_path, filepath\n\u001b[1;32m--> 700\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_top_k \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m previous \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_remove_checkpoint(trainer, previous, filepath):\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_remove_checkpoint(trainer, previous)\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:383\u001b[0m, in \u001b[0;36mModelCheckpoint._save_checkpoint\u001b[1;34m(self, trainer, filepath)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mis_global_zero:\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m logger \u001b[38;5;129;01min\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mloggers:\n\u001b[1;32m--> 383\u001b[0m         \u001b[43mlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproxy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:520\u001b[0m, in \u001b[0;36mWandbLogger.after_save_checkpoint\u001b[1;34m(self, checkpoint_callback)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mafter_save_checkpoint\u001b[39m(\u001b[38;5;28mself\u001b[39m, checkpoint_callback: ModelCheckpoint) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;66;03m# log checkpoints as artifacts\u001b[39;00m\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m checkpoint_callback\u001b[38;5;241m.\u001b[39msave_top_k \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 520\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_scan_and_log_checkpoints\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    522\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_callback \u001b[38;5;241m=\u001b[39m checkpoint_callback\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:605\u001b[0m, in \u001b[0;36mWandbLogger._scan_and_log_checkpoints\u001b[1;34m(self, checkpoint_callback)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    604\u001b[0m artifact \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39mArtifact(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_name, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, metadata\u001b[38;5;241m=\u001b[39mmetadata)\n\u001b[1;32m--> 605\u001b[0m \u001b[43martifact\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel.ckpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    606\u001b[0m aliases \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatest\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m==\u001b[39m checkpoint_callback\u001b[38;5;241m.\u001b[39mbest_model_path \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatest\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment\u001b[38;5;241m.\u001b[39mlog_artifact(artifact, aliases\u001b[38;5;241m=\u001b[39maliases)\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\wandb\\sdk\\artifacts\\artifact.py:1194\u001b[0m, in \u001b[0;36mArtifact.add_file\u001b[1;34m(self, local_path, name, is_tmp)\u001b[0m\n\u001b[0;32m   1191\u001b[0m     file_name_parts[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m b64_to_hex_id(digest)[:\u001b[38;5;241m20\u001b[39m]\n\u001b[0;32m   1192\u001b[0m     name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(file_name_parts))\n\u001b[1;32m-> 1194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_local_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdigest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdigest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\wandb\\sdk\\artifacts\\artifact.py:1471\u001b[0m, in \u001b[0;36mArtifact._add_local_file\u001b[1;34m(self, name, path, digest)\u001b[0m\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tempfile\u001b[38;5;241m.\u001b[39mNamedTemporaryFile(\u001b[38;5;28mdir\u001b[39m\u001b[38;5;241m=\u001b[39mget_staging_dir(), delete\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m   1470\u001b[0m     staging_path \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m-> 1471\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstaging_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1472\u001b[0m     os\u001b[38;5;241m.\u001b[39mchmod(staging_path, \u001b[38;5;241m0o400\u001b[39m)\n\u001b[0;32m   1474\u001b[0m entry \u001b[38;5;241m=\u001b[39m ArtifactManifestEntry(\n\u001b[0;32m   1475\u001b[0m     path\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   1476\u001b[0m     digest\u001b[38;5;241m=\u001b[39mdigest \u001b[38;5;129;01mor\u001b[39;00m md5_file_b64(staging_path),\n\u001b[0;32m   1477\u001b[0m     size\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mgetsize(staging_path),\n\u001b[0;32m   1478\u001b[0m     local_path\u001b[38;5;241m=\u001b[39mstaging_path,\n\u001b[0;32m   1479\u001b[0m )\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\shutil.py:276\u001b[0m, in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;66;03m# Windows, see:\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;66;03m# https://github.com/python/cpython/pull/7160#discussion_r195405230\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _WINDOWS \u001b[38;5;129;01mand\u001b[39;00m file_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 276\u001b[0m     \u001b[43m_copyfileobj_readinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfsrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCOPY_BUFSIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dst\n\u001b[0;32m    279\u001b[0m copyfileobj(fsrc, fdst)\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\shutil.py:187\u001b[0m, in \u001b[0;36m_copyfileobj_readinto\u001b[1;34m(fsrc, fdst, length)\u001b[0m\n\u001b[0;32m    185\u001b[0m         fdst\u001b[38;5;241m.\u001b[39mwrite(smv)\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 187\u001b[0m     fdst_write(mv)\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, audio_data_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
