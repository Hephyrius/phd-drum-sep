{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20b2a3bb-3d01-4f42-bc37-dff46522af7f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71d686e6-8847-4861-88f0-58141c363862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pywt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchaudio.pipelines import HDEMUCS_HIGH_MUSDB\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import random\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import wandb\n",
    "import auraloss\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "import pretty_midi\n",
    "import matplotlib.pyplot as plt\n",
    "from torchaudio.pipelines import HDEMUCS_HIGH_MUSDB\n",
    "print(torch.cuda.is_available())\n",
    "import plotly.graph_objects as go\n",
    "from torch.optim import lr_scheduler\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c82506-04c8-4200-9e63-26857aa176bd",
   "metadata": {},
   "source": [
    "# Set Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db3acd3b-d177-44d3-a3f4-35140f45e48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 3407\n",
    "torch.manual_seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "torch.cuda.manual_seed(seed_value)\n",
    "torch.cuda.manual_seed_all(seed_value)\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6182916a-aec1-4c05-8a08-4d2e44dfd979",
   "metadata": {},
   "source": [
    "# Construct Teh Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbe5ef07-9ab9-4e3e-9334-048f67ae25e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:/Github/phd-drum-sep/Data/musdb18hq/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e101d3bb-e001-42ff-90cc-42384739d506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test', 'train']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c52ab99f-41d2-4b7f-a179-90681a8a0a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = list(os.listdir(path+'train'))\n",
    "test = list(os.listdir(path+'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21aa39ee-b25f-4bdc-950a-9389eb93765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = ['drum', 'bass', 'other', 'vocals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f07f7f9c-2d6b-42b9-b5ac-0f4bd9aeb6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 4544.40it/s]\n"
     ]
    }
   ],
   "source": [
    "all_scenes = {}\n",
    "counter = 0\n",
    "sample_rate = 44100\n",
    "segment_length = sample_rate * 1\n",
    "\n",
    "for idx, val in tqdm(enumerate(test)):\n",
    "    p = path + 'test/' + val + \"/\"\n",
    "    info = torchaudio.info(f\"{p}mixture.wav\")\n",
    "    seconds = info.num_frames // 44100\n",
    "    for i in range(0, seconds - 1, 1):\n",
    "        start_point = i * 44100\n",
    "        if start_point + 44100 < info.num_frames:\n",
    "            all_scenes[counter] = {'music_path': p, 'start_point': start_point, 'length': 44100, 'frames' : info.num_frames}\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6d4eb9a-f08d-4452-a4ad-b9769a218278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_transcription_into_roll(transcription, frames):\n",
    "    # Determine your sampling frequency (frames per second)\n",
    "    fs = 44100\n",
    "    \n",
    "    piano_roll_length = int(frames)\n",
    "    \n",
    "    # Initialize the piano roll array\n",
    "    piano_roll = np.zeros((64, piano_roll_length))\n",
    "    \n",
    "    # Fill in the piano roll array\n",
    "    for note in transcription.instruments[0].notes:\n",
    "        # Convert start and end times to frame indices\n",
    "        start_frame = int(np.floor(note.start * fs))\n",
    "        end_frame = int(np.ceil(note.end * fs))\n",
    "        \n",
    "        # Set the corresponding frames to 1 (or note.velocity for a velocity-sensitive representation)\n",
    "        piano_roll[note.pitch, start_frame:end_frame] = 1  # Or use note.velocity\n",
    "        \n",
    "    roll = np.vstack([piano_roll[35:36, :], piano_roll[38:39, :], piano_roll[42:43, :], piano_roll[47:48, :], piano_roll[49:50, :]])\n",
    "    return roll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20988d30-a95e-4dca-ac19-a6f7cea95717",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b72a57b5-7115-421d-b26e-3ca3d21fef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrumDemucs(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(DrumDemucs, self).__init__()\n",
    "\n",
    "        self.loss_fn = auraloss.freq.MultiResolutionSTFTLoss(\n",
    "                    fft_sizes=[1024, 2048, 4096],\n",
    "                    hop_sizes=[256, 512, 1024],\n",
    "                    win_lengths=[1024, 2048, 4096],\n",
    "                    scale=\"mel\", \n",
    "                    n_bins=150,\n",
    "                    sample_rate=44100,\n",
    "                    device=\"cuda\"\n",
    "                )\n",
    "\n",
    "        self.loss_fn_2 = auraloss.time.SISDRLoss()\n",
    "\n",
    "        self.loss_fn_3 = torch.nn.L1Loss()\n",
    "\n",
    "        self.loss_used = 0\n",
    "\n",
    "        sources = ['drum',\n",
    "                   'noise',\n",
    "                   ]\n",
    "        \n",
    "        self.demucs_mixer =  torchaudio.models.HDemucs(\n",
    "            sources=sources,\n",
    "            audio_channels=7,\n",
    "            depth=6,\n",
    "        )\n",
    "\n",
    "        self.out_conv = nn.Conv1d(in_channels=7, out_channels=2, kernel_size=1)\n",
    "        self.out = nn.Conv1d(in_channels=2, out_channels=2, kernel_size=1)      \n",
    "\n",
    "\n",
    "    def compute_loss(self, outputs, ref_signals):\n",
    "        loss = self.loss_fn(outputs, ref_signals) + self.loss_fn_2(outputs, ref_signals) +  self.loss_fn_3(outputs, ref_signals)\n",
    "        return loss\n",
    "\n",
    "    def forward(self, audio, drumroll):\n",
    "        to_mix = torch.cat([audio, drumroll], axis=1)\n",
    "        out = self.demucs_mixer(to_mix)\n",
    "        out_2 = self.out_conv(out[:, 0, :, :])\n",
    "        out_2 = self.out(out_2)\n",
    "        # out_2 = torch.tanh(out_2)\n",
    "\n",
    "        return out_2\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop. It is independent of forward\n",
    "        audio, drum, drumroll = batch\n",
    "        \n",
    "        outputs = self.forward(audio, drumroll)\n",
    "        # print(outputs.size())\n",
    "\n",
    "        if batch_idx % 64 == 0:\n",
    "            input_signal = audio[0].cpu().detach().numpy().T\n",
    "            generated_signal = outputs[0].cpu().detach().numpy().T\n",
    "            drum_signal = drum[0].cpu().detach().numpy().T \n",
    "            wandb.log({'audio_input': [wandb.Audio(input_signal, caption=\"Input\", sample_rate=44100)]})\n",
    "            wandb.log({'audio_reference': [wandb.Audio(drum_signal, caption=\"Reference\", sample_rate=44100)]})\n",
    "            wandb.log({'audio_output': [wandb.Audio(generated_signal, caption=\"Output\", sample_rate=44100)]})\n",
    "             \n",
    "            for i in range(5):\n",
    "                wandb.log({f'drum_{i + 1}': [wandb.Audio(drumroll[0].cpu().detach().numpy()[i, :], caption=\"Output\", sample_rate=44100)]})\n",
    "\n",
    "\n",
    "        loss = self.compute_loss(outputs, drum)         \n",
    "\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Define your optimizer and optionally learning rate scheduler here\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.99)\n",
    "        return [optimizer], [scheduler]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "781bcca5-cded-4cf6-8ff6-555f6a55c53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DrumDemucs(\n",
       "  (loss_fn): MultiResolutionSTFTLoss(\n",
       "    (stft_losses): ModuleList(\n",
       "      (0-2): 3 x STFTLoss(\n",
       "        (spectralconv): SpectralConvergenceLoss()\n",
       "        (logstft): STFTMagnitudeLoss(\n",
       "          (distance): L1Loss()\n",
       "        )\n",
       "        (linstft): STFTMagnitudeLoss(\n",
       "          (distance): L1Loss()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (loss_fn_2): SISDRLoss()\n",
       "  (loss_fn_3): L1Loss()\n",
       "  (demucs_mixer): HDemucs(\n",
       "    (freq_encoder): ModuleList(\n",
       "      (0): _HEncLayer(\n",
       "        (conv): Conv2d(14, 48, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
       "        (norm1): Identity()\n",
       "        (rewrite): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (norm2): Identity()\n",
       "        (dconv): _DConv(\n",
       "          (layers): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
       "              (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "              (5): GLU(dim=1)\n",
       "              (6): _LayerScale()\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "              (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
       "              (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "              (5): GLU(dim=1)\n",
       "              (6): _LayerScale()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): _HEncLayer(\n",
       "        (conv): Conv2d(48, 96, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
       "        (norm1): Identity()\n",
       "        (rewrite): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (norm2): Identity()\n",
       "        (dconv): _DConv(\n",
       "          (layers): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
       "              (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "              (5): GLU(dim=1)\n",
       "              (6): _LayerScale()\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "              (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
       "              (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "              (5): GLU(dim=1)\n",
       "              (6): _LayerScale()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): _HEncLayer(\n",
       "        (conv): Conv2d(96, 192, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
       "        (norm1): Identity()\n",
       "        (rewrite): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (norm2): Identity()\n",
       "        (dconv): _DConv(\n",
       "          (layers): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
       "              (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "              (5): GLU(dim=1)\n",
       "              (6): _LayerScale()\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "              (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
       "              (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "              (5): GLU(dim=1)\n",
       "              (6): _LayerScale()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): _HEncLayer(\n",
       "        (conv): Conv2d(192, 384, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
       "        (norm1): Identity()\n",
       "        (rewrite): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (norm2): Identity()\n",
       "        (dconv): _DConv(\n",
       "          (layers): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
       "              (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
       "              (5): GLU(dim=1)\n",
       "              (6): _LayerScale()\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "              (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
       "              (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
       "              (5): GLU(dim=1)\n",
       "              (6): _LayerScale()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): _HEncLayer(\n",
       "        (conv): Conv2d(384, 768, kernel_size=(8, 1), stride=(4, 1))\n",
       "        (norm1): GroupNorm(4, 768, eps=1e-05, affine=True)\n",
       "        (rewrite): Conv2d(768, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (norm2): GroupNorm(4, 1536, eps=1e-05, affine=True)\n",
       "        (dconv): _DConv(\n",
       "          (layers): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (1): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): _BLSTM(\n",
       "                (lstm): LSTM(192, 192, num_layers=2, bidirectional=True)\n",
       "                (linear): Linear(in_features=384, out_features=192, bias=True)\n",
       "              )\n",
       "              (4): _LocalState(\n",
       "                (content): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "                (query): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "                (key): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "                (query_decay): Conv1d(192, 16, kernel_size=(1,), stride=(1,))\n",
       "                (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              )\n",
       "              (5): Conv1d(192, 1536, kernel_size=(1,), stride=(1,))\n",
       "              (6): GroupNorm(1, 1536, eps=1e-05, affine=True)\n",
       "              (7): GLU(dim=1)\n",
       "              (8): _LayerScale()\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "              (1): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): _BLSTM(\n",
       "                (lstm): LSTM(192, 192, num_layers=2, bidirectional=True)\n",
       "                (linear): Linear(in_features=384, out_features=192, bias=True)\n",
       "              )\n",
       "              (4): _LocalState(\n",
       "                (content): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "                (query): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "                (key): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "                (query_decay): Conv1d(192, 16, kernel_size=(1,), stride=(1,))\n",
       "                (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              )\n",
       "              (5): Conv1d(192, 1536, kernel_size=(1,), stride=(1,))\n",
       "              (6): GroupNorm(1, 1536, eps=1e-05, affine=True)\n",
       "              (7): GLU(dim=1)\n",
       "              (8): _LayerScale()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): _HEncLayer(\n",
       "        (conv): Conv1d(768, 1536, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "        (norm1): GroupNorm(4, 1536, eps=1e-05, affine=True)\n",
       "        (rewrite): Conv1d(1536, 3072, kernel_size=(1,), stride=(1,))\n",
       "        (norm2): GroupNorm(4, 3072, eps=1e-05, affine=True)\n",
       "        (dconv): _DConv(\n",
       "          (layers): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (1): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): _BLSTM(\n",
       "                (lstm): LSTM(384, 384, num_layers=2, bidirectional=True)\n",
       "                (linear): Linear(in_features=768, out_features=384, bias=True)\n",
       "              )\n",
       "              (4): _LocalState(\n",
       "                (content): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "                (query): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "                (key): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "                (query_decay): Conv1d(384, 16, kernel_size=(1,), stride=(1,))\n",
       "                (proj): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              )\n",
       "              (5): Conv1d(384, 3072, kernel_size=(1,), stride=(1,))\n",
       "              (6): GroupNorm(1, 3072, eps=1e-05, affine=True)\n",
       "              (7): GLU(dim=1)\n",
       "              (8): _LayerScale()\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "              (1): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): _BLSTM(\n",
       "                (lstm): LSTM(384, 384, num_layers=2, bidirectional=True)\n",
       "                (linear): Linear(in_features=768, out_features=384, bias=True)\n",
       "              )\n",
       "              (4): _LocalState(\n",
       "                (content): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "                (query): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "                (key): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "                (query_decay): Conv1d(384, 16, kernel_size=(1,), stride=(1,))\n",
       "                (proj): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              )\n",
       "              (5): Conv1d(384, 3072, kernel_size=(1,), stride=(1,))\n",
       "              (6): GroupNorm(1, 3072, eps=1e-05, affine=True)\n",
       "              (7): GLU(dim=1)\n",
       "              (8): _LayerScale()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (freq_decoder): ModuleList(\n",
       "      (0): _HDecLayer(\n",
       "        (conv_tr): ConvTranspose1d(1536, 768, kernel_size=(4,), stride=(2,))\n",
       "        (norm2): GroupNorm(4, 768, eps=1e-05, affine=True)\n",
       "        (rewrite): Conv1d(1536, 3072, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm1): GroupNorm(4, 3072, eps=1e-05, affine=True)\n",
       "      )\n",
       "      (1): _HDecLayer(\n",
       "        (conv_tr): ConvTranspose2d(768, 384, kernel_size=(8, 1), stride=(4, 1))\n",
       "        (norm2): GroupNorm(4, 384, eps=1e-05, affine=True)\n",
       "        (rewrite): Conv2d(768, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm1): GroupNorm(4, 1536, eps=1e-05, affine=True)\n",
       "      )\n",
       "      (2): _HDecLayer(\n",
       "        (conv_tr): ConvTranspose2d(384, 192, kernel_size=(8, 1), stride=(4, 1))\n",
       "        (norm2): Identity()\n",
       "        (rewrite): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm1): Identity()\n",
       "      )\n",
       "      (3): _HDecLayer(\n",
       "        (conv_tr): ConvTranspose2d(192, 96, kernel_size=(8, 1), stride=(4, 1))\n",
       "        (norm2): Identity()\n",
       "        (rewrite): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm1): Identity()\n",
       "      )\n",
       "      (4): _HDecLayer(\n",
       "        (conv_tr): ConvTranspose2d(96, 48, kernel_size=(8, 1), stride=(4, 1))\n",
       "        (norm2): Identity()\n",
       "        (rewrite): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm1): Identity()\n",
       "      )\n",
       "      (5): _HDecLayer(\n",
       "        (conv_tr): ConvTranspose2d(48, 28, kernel_size=(8, 1), stride=(4, 1))\n",
       "        (norm2): Identity()\n",
       "        (rewrite): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm1): Identity()\n",
       "      )\n",
       "    )\n",
       "    (time_encoder): ModuleList(\n",
       "      (0): _HEncLayer(\n",
       "        (conv): Conv1d(7, 48, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "        (norm1): Identity()\n",
       "        (rewrite): Conv1d(48, 96, kernel_size=(1,), stride=(1,))\n",
       "        (norm2): Identity()\n",
       "        (dconv): _DConv(\n",
       "          (layers): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
       "              (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "              (5): GLU(dim=1)\n",
       "              (6): _LayerScale()\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "              (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
       "              (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "              (5): GLU(dim=1)\n",
       "              (6): _LayerScale()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): _HEncLayer(\n",
       "        (conv): Conv1d(48, 96, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "        (norm1): Identity()\n",
       "        (rewrite): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "        (norm2): Identity()\n",
       "        (dconv): _DConv(\n",
       "          (layers): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
       "              (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "              (5): GLU(dim=1)\n",
       "              (6): _LayerScale()\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "              (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
       "              (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "              (5): GLU(dim=1)\n",
       "              (6): _LayerScale()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): _HEncLayer(\n",
       "        (conv): Conv1d(96, 192, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "        (norm1): Identity()\n",
       "        (rewrite): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "        (norm2): Identity()\n",
       "        (dconv): _DConv(\n",
       "          (layers): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
       "              (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "              (5): GLU(dim=1)\n",
       "              (6): _LayerScale()\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "              (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
       "              (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "              (5): GLU(dim=1)\n",
       "              (6): _LayerScale()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): _HEncLayer(\n",
       "        (conv): Conv1d(192, 384, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "        (norm1): Identity()\n",
       "        (rewrite): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "        (norm2): Identity()\n",
       "        (dconv): _DConv(\n",
       "          (layers): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "              (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
       "              (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
       "              (5): GLU(dim=1)\n",
       "              (6): _LayerScale()\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "              (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
       "              (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
       "              (5): GLU(dim=1)\n",
       "              (6): _LayerScale()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): _HEncLayer(\n",
       "        (conv): Conv1d(384, 768, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "        (norm1): GroupNorm(4, 768, eps=1e-05, affine=True)\n",
       "        (rewrite): Identity()\n",
       "        (norm2): Identity()\n",
       "        (dconv): Identity()\n",
       "      )\n",
       "    )\n",
       "    (time_decoder): ModuleList(\n",
       "      (0): _HDecLayer(\n",
       "        (conv_tr): ConvTranspose1d(768, 384, kernel_size=(8,), stride=(4,))\n",
       "        (norm2): GroupNorm(4, 384, eps=1e-05, affine=True)\n",
       "        (rewrite): Identity()\n",
       "        (norm1): Identity()\n",
       "      )\n",
       "      (1): _HDecLayer(\n",
       "        (conv_tr): ConvTranspose1d(384, 192, kernel_size=(8,), stride=(4,))\n",
       "        (norm2): Identity()\n",
       "        (rewrite): Conv1d(384, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm1): Identity()\n",
       "      )\n",
       "      (2): _HDecLayer(\n",
       "        (conv_tr): ConvTranspose1d(192, 96, kernel_size=(8,), stride=(4,))\n",
       "        (norm2): Identity()\n",
       "        (rewrite): Conv1d(192, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm1): Identity()\n",
       "      )\n",
       "      (3): _HDecLayer(\n",
       "        (conv_tr): ConvTranspose1d(96, 48, kernel_size=(8,), stride=(4,))\n",
       "        (norm2): Identity()\n",
       "        (rewrite): Conv1d(96, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm1): Identity()\n",
       "      )\n",
       "      (4): _HDecLayer(\n",
       "        (conv_tr): ConvTranspose1d(48, 14, kernel_size=(8,), stride=(4,))\n",
       "        (norm2): Identity()\n",
       "        (rewrite): Conv1d(48, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (norm1): Identity()\n",
       "      )\n",
       "    )\n",
       "    (freq_emb): _ScaledEmbedding(\n",
       "      (embedding): Embedding(512, 48)\n",
       "    )\n",
       "  )\n",
       "  (out_conv): Conv1d(7, 2, kernel_size=(1,), stride=(1,))\n",
       "  (out): Conv1d(2, 2, kernel_size=(1,), stride=(1,))\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DrumDemucs.load_from_checkpoint('D:/Github/phd-drum-sep/analysis/demucs_model_analysis/checkpoint/epoch_380.ckpt')\n",
    "model.to('cpu')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79d11190-4e68-41f8-ae19-36d8199c1643",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_audio = collections.OrderedDict()\n",
    "cache_drumroll = collections.OrderedDict()\n",
    "\n",
    "def add_to_cache(cache, key, value, size=10):\n",
    "    if key in cache:\n",
    "        # Move to the end to avoid being removed soon\n",
    "        cache.move_to_end(key)\n",
    "    else:\n",
    "        cache[key] = value\n",
    "        # Remove the oldest item if cache exceeds the size limit\n",
    "        if len(cache) >= size:\n",
    "            cache.popitem(last=False)\n",
    "\n",
    "\n",
    "def load_audio(path, start_point, filename):\n",
    "    audio_tensors = []\n",
    "\n",
    "    cache_key = (path+'/'+filename)\n",
    "    if cache_key in cache_audio:\n",
    "        waveform = cache_audio[cache_key]\n",
    "    else:\n",
    "        waveform, _ = torchaudio.load(f\"{path}/{filename}\")\n",
    "        add_to_cache(cache_audio, cache_key, waveform)\n",
    "\n",
    "    segment = waveform[:, start_point: start_point + segment_length]\n",
    "    audio_tensors.append(segment)\n",
    "    \n",
    "    return torch.cat(audio_tensors, dim=0)\n",
    "\n",
    "def load_roll(path, start_point, frames):\n",
    "    midi = path + '/mixture.wav.mid'\n",
    "    transcription = pretty_midi.PrettyMIDI(midi)\n",
    "\n",
    "    cache_key = (path)\n",
    "    if cache_key in cache_drumroll:\n",
    "        roll = cache_drumroll[cache_key]\n",
    "    else:\n",
    "        roll = turn_transcription_into_roll(transcription, frames)\n",
    "        add_to_cache(cache_drumroll, cache_key, roll)\n",
    "\n",
    "    roll = roll[:, start_point: start_point + segment_length]\n",
    "    return torch.from_numpy(roll).float()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21855663-0d63-438f-8fce-c1c7f1b36184",
   "metadata": {},
   "source": [
    "# Seperate specific tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb99f913-f31e-4fc9-95ac-2ee1ad63023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in tqdm(idxs[:1]):\n",
    "audios = []\n",
    "idx = 1100\n",
    "sample =  all_scenes[idx]\n",
    "\n",
    "audio_path = sample['music_path']\n",
    "\n",
    "start_point = sample['start_point']\n",
    "\n",
    "mixture_tensor = load_audio(audio_path, start_point,'mixture.wav').unsqueeze(0).to(model.device)\n",
    "drum_tensor = load_audio(audio_path, start_point,'drums.wav').unsqueeze(0).to(model.device)\n",
    "roll_tensor = load_roll(audio_path, start_point, sample['frames'])#\n",
    "\n",
    "for i in range(5):\n",
    "    roll_tensor_0 = (torch.zeros_like(roll_tensor) + torch.ones_like(roll_tensor)) / 2\n",
    "    roll_tensor_0[i, :] = roll_tensor[i, :]\n",
    "    roll_tensor_0 = roll_tensor_0.unsqueeze(0).to(model.device)\n",
    "    sep = model(mixture_tensor, roll_tensor_0)\n",
    "    audios.append(sep)\n",
    "\n",
    "sep = model(mixture_tensor, roll_tensor.unsqueeze(0).to(model.device))\n",
    "audios.append(sep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a00457-307d-4743-9784-9f4cdae73730",
   "metadata": {},
   "source": [
    "# SISNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3228c44b-1310-4836-9cdc-acc7afacb04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_sdr(references, estimates):\n",
    "    \"\"\"\n",
    "    Compute the SDR according to the MDX challenge definition.\n",
    "    Adapted from AIcrowd/music-demixing-challenge-starter-kit (MIT license)\n",
    "    \"\"\"\n",
    "    assert references.dim() == 4\n",
    "    assert estimates.dim() == 4\n",
    "    delta = 1e-7  # avoid numerical errors\n",
    "    num = torch.sum(torch.square(references), dim=(2, 3))\n",
    "    den = torch.sum(torch.square(references - estimates), dim=(2, 3))\n",
    "    num += delta\n",
    "    den += delta\n",
    "    scores = 10 * torch.log10(num / den)\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59d7a589-3905-417f-8a2b-ff80ff6999fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 12396/12396 [49:22<00:00,  4.18it/s]\n"
     ]
    }
   ],
   "source": [
    "idxs = list(all_scenes)\n",
    "\n",
    "sdr = {}\n",
    "sdr_underlying = {}\n",
    "current_track = \"\"\n",
    "for idx in tqdm(idxs):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        audio_path = sample['music_path']\n",
    "        \n",
    "        if audio_path != current_track:\n",
    "            current_track = audio_path\n",
    "            sdr[current_track] = []\n",
    "            sdr_underlying[current_track] = []\n",
    "        \n",
    "        sample =  all_scenes[idx]\n",
    "        start_point = sample['start_point']\n",
    "    \n",
    "        mixture_tensor = load_audio(audio_path, start_point,'mixture.wav').unsqueeze(0).to(model.device)\n",
    "        drum_tensor = load_audio(audio_path, start_point,'drums.wav').unsqueeze(0).to(model.device)\n",
    "        roll_tensor = load_roll(audio_path, start_point, sample['frames']).unsqueeze(0).to(model.device)\n",
    "        sep = model(mixture_tensor, roll_tensor)\n",
    "    \n",
    "        x_ = mixture_tensor.detach().unsqueeze(2)\n",
    "        y = drum_tensor.unsqueeze(2)\n",
    "        y_hat = sep.detach().unsqueeze(2)\n",
    "        \n",
    "        nsdr = new_sdr(y, y_hat)\n",
    "        nsdr_underlying = new_sdr(y, x_)\n",
    "\n",
    "        sdr[current_track].append(nsdr)\n",
    "    \n",
    "        sdr_underlying[current_track].append(nsdr_underlying)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38f821bb-97e5-462e-b188-bc04f63b4f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_sdrs = {}\n",
    "\n",
    "for name in list(sdr.keys()):\n",
    "    left = []\n",
    "    right = []\n",
    "    sdrs = sdr[name]\n",
    "\n",
    "    for value in sdrs:\n",
    "        left.append(value[0][0].item())\n",
    "        right.append(value[0][1].numpy().item())\n",
    "\n",
    "    l = np.median(left)\n",
    "    r = np.median(right)\n",
    "\n",
    "    median_sdrs[name] = {'left_median': l, 'right_median':r}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1513a7ef-8354-4a9d-aaaf-34882bf9eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lefts = []\n",
    "rights = []\n",
    "for name in list(median_sdrs.keys()):\n",
    "    values = median_sdrs[name]\n",
    "    lefts.append(values['left_median'])\n",
    "    rights.append(values['right_median'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a20ccac-c259-4638-8d66-653fd3e77093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.7577788829803467, 3.9401825070381165)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = np.median(lefts)\n",
    "r = np.median(rights)\n",
    "l, r"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bdbeedae-bfd7-4a75-8fc8-836de012d0bc",
   "metadata": {},
   "source": [
    "sdr[idx].numpy().item() , sdr_underlying[idx].numpy().item()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "621dd451-c4d7-4977-b1fb-9d11a54be6c9",
   "metadata": {},
   "source": [
    "avg = 0\n",
    "total = 0\n",
    "for idx, val in enumerate(sdr):\n",
    "    try:\n",
    "        val = (sdr[idx].numpy().item() -  sdr_underlying[idx].numpy().item())\n",
    "        if math.isnan(val) == False and math.isinf(val) == False:\n",
    "            # print((sdr[idx][2] -  sdr_underlying[idx][2]))\n",
    "            avg += val\n",
    "            total += 1\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "print(\"sdr improvement\", avg/total)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "94a611bc-3a76-4ba5-b828-5f69c5f0b5b5",
   "metadata": {},
   "source": [
    "avg = 0\n",
    "total = 0\n",
    "for idx, val in enumerate(sdr):\n",
    "    try:\n",
    "        val = sdr[idx].numpy().item()\n",
    "        if math.isnan(val) == False and math.isinf(val) == False:\n",
    "            # print((sdr[idx][2] -  sdr_underlying[idx][2]))\n",
    "            print(val)\n",
    "            avg += val\n",
    "            total += 1\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "print(\"sdr\", avg/total)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4e611fee-5741-44c2-9980-220bc464f715",
   "metadata": {},
   "source": [
    "import math\n",
    "avg = 0\n",
    "total = 0\n",
    "for idx, val in enumerate(si_snrs):\n",
    "    try:\n",
    "        val = (si_snrs[idx][2] -  si_snrs_underlying[idx][2])\n",
    "        if math.isnan(val) == False and math.isinf(val) == False:\n",
    "            # print((si_snrs[idx][2] -  si_snrs_underlying[idx][2]))\n",
    "            avg += val\n",
    "            total += 1\n",
    "    except:\n",
    "        pass\n",
    "print(\"si-snr improvement\", avg/total)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cdfb51e6-bd08-439a-b609-8bad5182f0be",
   "metadata": {},
   "source": [
    "# ZEROING!"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ccb5802-d17d-45ab-bb51-a4434b3d421a",
   "metadata": {},
   "source": [
    "idxs = list(all_scenes)\n",
    "si_snrs_0 = []\n",
    "si_snrs_underlying_0 = []\n",
    "sdr_0 = []\n",
    "sdr_underlying_0 = []\n",
    "for idx in tqdm(idxs):\n",
    "    sample =  all_scenes[idx]\n",
    "\n",
    "    audio_path = sample['music_path']\n",
    "\n",
    "    start_point = sample['start_point']\n",
    "\n",
    "    mixture_tensor = load_audio(audio_path, start_point,'mixture.wav').unsqueeze(0).to(model.device)\n",
    "    drum_tensor = load_audio(audio_path, start_point,'drums.wav').unsqueeze(0).to(model.device)\n",
    "    roll_tensor = load_roll(audio_path, start_point, sample['frames']).unsqueeze(0).to(model.device)\n",
    "    roll_tensor_0 = torch.zeros_like(roll_tensor).to(model.device)\n",
    "    sep = model(mixture_tensor, roll_tensor_0)\n",
    "\n",
    "    sisnr_l = calculate_si_snr(drum_tensor.squeeze(0)[0].cpu().numpy(), sep.squeeze(0)[0].detach().cpu().numpy())\n",
    "    sisnr_r = calculate_si_snr(drum_tensor.squeeze(0)[1].cpu().numpy(), sep.squeeze(0)[1].detach().cpu().numpy())\n",
    "    sisnr_avg = (sisnr_l + sisnr_r) / 2\n",
    "    si_snrs_0.append([sisnr_l, sisnr_r, sisnr_avg])\n",
    "\n",
    "    sdr_l = calculate_sdr(drum_tensor.squeeze(0)[0].cpu().numpy(), sep.squeeze(0)[0].detach().cpu().numpy())\n",
    "    sdr_r = calculate_sdr(drum_tensor.squeeze(0)[1].cpu().numpy(), sep.squeeze(0)[1].detach().cpu().numpy())\n",
    "    sdr_avg = (sdr_l + sdr_r) / 2\n",
    "    sdr_0.append([sdr_l, sdr_r, sdr_avg])\n",
    "\n",
    "    ################################################################\n",
    "    \n",
    "    sisnr_l = calculate_si_snr(drum_tensor.squeeze(0)[0].cpu().numpy(), mixture_tensor.squeeze(0)[0].detach().cpu().numpy())\n",
    "    sisnr_r = calculate_si_snr(drum_tensor.squeeze(0)[1].cpu().numpy(), mixture_tensor.squeeze(0)[1].detach().cpu().numpy())\n",
    "    sisnr_avg = (sisnr_l + sisnr_r) / 2\n",
    "    si_snrs_underlying_0.append([sisnr_l, sisnr_r, sisnr_avg])\n",
    "\n",
    "    sdr_l = calculate_sdr(drum_tensor.squeeze(0)[0].cpu().numpy(), mixture_tensor.squeeze(0)[0].detach().cpu().numpy())\n",
    "    sdr_r = calculate_sdr(drum_tensor.squeeze(0)[1].cpu().numpy(), mixture_tensor.squeeze(0)[1].detach().cpu().numpy())\n",
    "    sdr_avg = (sdr_l + sdr_r) / 2\n",
    "    sdr_underlying_0.append([sdr_l, sdr_r, sdr_avg])\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b601049-d58b-4f93-8795-1882016a68ef",
   "metadata": {},
   "source": [
    "import math\n",
    "avg = 0\n",
    "total = 0\n",
    "for idx, val in enumerate(si_snrs_0):\n",
    "    try:\n",
    "        val = (si_snrs_0[idx][2] -  si_snrs_underlying_0[idx][2])\n",
    "        if math.isnan(val) == False and math.isinf(val) == False:\n",
    "            # print((si_snrs_0[idx][2] -  si_snrs_underlying_0[idx][2]))\n",
    "            avg += val\n",
    "            total += 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(\"si-snri improvement all 0\", avg/total)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a8bfd8e-d0fe-441a-972b-c61166f5225d",
   "metadata": {},
   "source": [
    "import math\n",
    "avg = 0\n",
    "total = 0\n",
    "for idx, val in enumerate(sdr_0):\n",
    "    try:\n",
    "        val = (sdr_0[idx][2] -  sdr_underlying_0[idx][2])\n",
    "        if math.isnan(val) == False and math.isinf(val) == False:\n",
    "            # print((si_snrs_0[idx][2] -  si_snrs_underlying_0[idx][2]))\n",
    "            avg += val\n",
    "            total += 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(\"sdr improvement all 0\", avg/total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
